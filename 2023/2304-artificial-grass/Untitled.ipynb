{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3c0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28ef11",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915ad41a",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb55f529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provider</th>\n",
       "      <th>text_url</th>\n",
       "      <th>text</th>\n",
       "      <th>names_url</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial Grass GB</td>\n",
       "      <td>https://www.artificialgrassgb.co.uk/</td>\n",
       "      <td>\\nWhy choose artificial grass over real grass?...</td>\n",
       "      <td>https://www.artificialgrassgb.co.uk/</td>\n",
       "      <td>Velvet, English Garden, Cadiz, Gold, Forest, L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grass Direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.grass-direct.co.uk/artificial-grass</td>\n",
       "      <td>Oasis, Sydney, Bordeaux, Antigua, Geneva, Melb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Express grass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://expressgrass.com/artificial-grass.html</td>\n",
       "      <td>Woodstock, Classic, Hartfield, Chartwell, Oakh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Easigrass</td>\n",
       "      <td>https://www.easigrass.com/areas-we-cover/londo...</td>\n",
       "      <td>No Mud, No Mess, No Mowing.\\n\\nArtificial Gras...</td>\n",
       "      <td>https://www.easigrass.com/easi-grass-products/...</td>\n",
       "      <td>Mayfair, Belgravia, Chelsea, Kensington, Holla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nustone</td>\n",
       "      <td>https://nustone.co.uk/product-category/artific...</td>\n",
       "      <td>Artificial Grass will transform your garden an...</td>\n",
       "      <td>https://nustone.co.uk/product-category/artific...</td>\n",
       "      <td>Tahoe, Cleveland, Santa Fe, Nebraska, Ozark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              provider                                           text_url   \n",
       "0  Artificial Grass GB               https://www.artificialgrassgb.co.uk/  \\\n",
       "1         Grass Direct                                                NaN   \n",
       "2        Express grass                                                NaN   \n",
       "3            Easigrass  https://www.easigrass.com/areas-we-cover/londo...   \n",
       "4              Nustone  https://nustone.co.uk/product-category/artific...   \n",
       "\n",
       "                                                text   \n",
       "0  \\nWhy choose artificial grass over real grass?...  \\\n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  No Mud, No Mess, No Mowing.\\n\\nArtificial Gras...   \n",
       "4  Artificial Grass will transform your garden an...   \n",
       "\n",
       "                                           names_url   \n",
       "0               https://www.artificialgrassgb.co.uk/  \\\n",
       "1    https://www.grass-direct.co.uk/artificial-grass   \n",
       "2     https://expressgrass.com/artificial-grass.html   \n",
       "3  https://www.easigrass.com/easi-grass-products/...   \n",
       "4  https://nustone.co.uk/product-category/artific...   \n",
       "\n",
       "                                               names  \n",
       "0  Velvet, English Garden, Cadiz, Gold, Forest, L...  \n",
       "1  Oasis, Sydney, Bordeaux, Antigua, Geneva, Melb...  \n",
       "2  Woodstock, Classic, Hartfield, Chartwell, Oakh...  \n",
       "3  Mayfair, Belgravia, Chelsea, Kensington, Holla...  \n",
       "4        Tahoe, Cleveland, Santa Fe, Nebraska, Ozark  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"raw-data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96419888",
   "metadata": {},
   "source": [
    "## Text\n",
    "We need to clean the text data in the title so that we can do some proper text mining. This includes\n",
    "\n",
    "- Standardising\n",
    "- Tokenising and removing stop words\n",
    "- Lemmatising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60c061",
   "metadata": {},
   "source": [
    "\n",
    "### Standardising\n",
    "\n",
    "We will remove punctuation and clean any other symbols/words as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "735f6dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     why choose artificial grass over real grass un...\n",
      "1                                                   NaN\n",
      "2                                                   NaN\n",
      "3     no mud no mess no mowing  artificial grass in ...\n",
      "4     artificial grass will transform your garden an...\n",
      "5     professional artificial turf installation in l...\n",
      "6     no more muddy feet get the perfect artificial ...\n",
      "7                                                   NaN\n",
      "8     artificial grass is great for people in london...\n",
      "9                                                   NaN\n",
      "10    looks great it looks luscious and full of life...\n",
      "11    lush green grass all year round fake grass loo...\n",
      "12    if you love grass but don’t want the mess mud ...\n",
      "13    make the most of your garden with trulawn lowm...\n",
      "14    all year round play area no more mud  artifici...\n",
      "15    pet and child friendly artificial grass ur art...\n",
      "16    say hello to our green grass the artificial gr...\n",
      "17    struggling to maintain your lawn looking pleas...\n",
      "18    want to spruce up your garden without the adde...\n",
      "19    artificial grass can transform your outside sp...\n",
      "20    do you love a luscious lawn but dislike the co...\n",
      "21                                                  NaN\n",
      "22    great for families soft underfoot with a natur...\n",
      "23                                                  NaN\n",
      "24                                                  NaN\n",
      "25    primarily there are three main groups of peopl...\n",
      "26                                                  NaN\n",
      "27    no mowing • no mud • no watering • pet friendl...\n",
      "28                                                  NaN\n",
      "29    artificial grass will transform any garden int...\n",
      "30    dirt free lawn eliminate mowing safe for child...\n",
      "31    artificial grass is continuing to rise in popu...\n",
      "32    the luxigraze product range creates a safe sty...\n",
      "33    do you dream of a lowmaintenance weed free gar...\n",
      "34                                                  NaN\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# make text lower case\n",
    "text = df[\"text\"].str.lower()\n",
    "\n",
    "# replace values within titles\n",
    "\n",
    "# function to loop through the column and replace substrings\n",
    "def replace_values(text, dic):\n",
    "    for x, y in dic.items():\n",
    "        text = text.str.replace(x, y, regex=True)\n",
    "    return text\n",
    "\n",
    "# list of values to be replaced, including punctuation\n",
    "replace_dict = {\"&amp;\": \" \", #xml syntax for &\n",
    "                \"\\n\":\" \",\n",
    "                \"[!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~“”-]\": \" \",\n",
    "                \"  \": \" \", #double space\n",
    "                \"’s\" :\"\",  \n",
    "                \"low maintenance\" :\"lowmaintenance\",  \n",
    "                \"’m\" : \"\",\n",
    "                \"y'all\": \"you all\",\n",
    "                \"i'm\": \"i am\",\n",
    "                \"i've\": \"i have\",\n",
    "                \"it'll\": \"it will\",\n",
    "                \"we're\": \"we are\",\n",
    "                \"i'd\": \"i would\",\n",
    "               }\n",
    "                \n",
    "# apply function\n",
    "text = replace_values(text, replace_dict)\n",
    "\n",
    "# strip white space at the end\n",
    "text = text.str.strip()\n",
    "\n",
    "# add new column to dataframe\n",
    "df[\"text_standardised\"] = text\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107f1d61",
   "metadata": {},
   "source": [
    "### Remove stop words\n",
    "\n",
    "We now remove stop words that don't really help to identify the sentiment or topic of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08215c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lisa.hornung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9633c39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4175c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"choose artificial grass real grass unlike real grass artificial grass give perfect looking lawn year round usable lawn year round there's mowing mud bald patches weeds waterlogged soggy lawns giving even time enjoy garden artificial grass installed artificial grass installed literally anywhere standard garden installations including decking flagstones block paving concrete tarmac areas balconies terraces schools nurseries artificial grass great commercial use creating big statement business said using artificial grass events whether public private safe children yes perfect choice create safe play area children year round supply softness grass available high level bounce back help keep children safe matter play activities suitable pets yes grass pet friendly fact many kennels use artificial grass colour grass affected pet mess mess easily removed residue easily rinsed away tough stains soap detergent used followed hosing artificial grass require maintenance lowmaintenance product clearly grass never grow mowing little light periodic clearing away debris like leaves seed pods occasional brushing that's required\", ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "# create empty list to store text without stop words\n",
    "text_no_stop_words = []\n",
    "\n",
    "# iterate through each word in each text row and append those that are no stop words\n",
    "# split titles into substrings using space as delimiter\n",
    "for words in text.str.split(\" \"):\n",
    "    x = []\n",
    "    try:\n",
    "        for word in words:\n",
    "            if word not in stop_words:\n",
    "                x.append(word)\n",
    "    \n",
    "    #exception for missing data\n",
    "    except TypeError:\n",
    "        x.append(\" \")\n",
    "    text_no_stop_words.append(x)\n",
    "\n",
    "# join titles back together\n",
    "text_no_stop_words = [\" \".join(items) for items in text_no_stop_words]\n",
    "\n",
    "# add title to dataframe\n",
    "df[\"text_no_stop_words\"] = text_no_stop_words\n",
    "\n",
    "print(text_no_stop_words[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ace9d7",
   "metadata": {},
   "source": [
    "## Lemmatize\n",
    "\n",
    "Now we want to reduce the inflectional forms of each word into a common base or root. We do this by using a lemmatiser that detects the lemma for each word.\n",
    "\n",
    "Read [this article](https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/) for more information on the difference betweent stemmatising and lemmatising.\n",
    "\n",
    "You will need to install spacy and download the en_core_web_sm package. Explanation [here](https://spacy.io/usage).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47693eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "# load model from SpaCy\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# create new list to store lemmatised titles\n",
    "text_lemmatised = []\n",
    "\n",
    "# iterate through each word in each title and append the lemmatised version of the word\n",
    "for words in pd.Series(text_no_stop_words):\n",
    "    x = []\n",
    "    for word in nlp(words):\n",
    "        x.append(word.lemma_)\n",
    "    text_lemmatised.append(x)\n",
    "\n",
    "# join titles back together\n",
    "text_lemmatised = [\" \".join(items) for items in text_lemmatised]\n",
    "\n",
    "df[\"text_lemmatised\"] = text_lemmatised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c43ae",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236b742",
   "metadata": {},
   "source": [
    "- [How To Perform Sentiment Analysis in Python 3 Using the Natural Language Toolkit (NLTK)](https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk)\n",
    "- [Sentiment Analysis on Reddit News Headlines with Python’s Natural Language Toolkit (NLTK)](https://www.learndatasci.com/tutorials/sentiment-analysis-reddit-headlines-pythons-nltk/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b64ac",
   "metadata": {},
   "source": [
    "## Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "60649f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def process_text(text):\n",
    "    tokens = []\n",
    "    lines = []\n",
    "    for line in text:\n",
    "        toks = tokenizer.tokenize(line)\n",
    "        toks = [t.lower() for t in toks if t.lower() not in stop_words]\n",
    "        tokens.extend(toks)\n",
    "        lines.append(toks)\n",
    "    \n",
    "    return tokens, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e2e2c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grass</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artificial</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawn</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garden</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>lawncare</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>landscaper</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>developer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>dense</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>tolerant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>973 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Count\n",
       "0         grass    207\n",
       "1    artificial    123\n",
       "2          lawn     66\n",
       "3        garden     50\n",
       "4           pet     50\n",
       "..          ...    ...\n",
       "968    lawncare      1\n",
       "969  landscaper      1\n",
       "970   developer      1\n",
       "971       dense      1\n",
       "972    tolerant      1\n",
       "\n",
       "[973 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokens, line_tokens = process_text(df[\"text_lemmatised\"])\n",
    "df[\"tokens\"] = line_tokens\n",
    "\n",
    "word_freq = nltk.FreqDist(text_tokens)\n",
    "word_freq = word_freq.most_common()\n",
    "word_freq = pd.DataFrame(word_freq, columns=[\"Word\", \"Count\"])\n",
    "\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d93e1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add provider count\n",
    "\n",
    "provider = []\n",
    "for word in word_freq[\"Word\"]:\n",
    "    counter = 0\n",
    "    for i in range(len(df)):\n",
    "        if word in df[\"tokens\"].iloc[i]:\n",
    "            counter+=1\n",
    "    provider.append(counter)\n",
    "\n",
    "word_freq[\"Provider_count\"] = provider\n",
    "\n",
    "#export output\n",
    "word_freq.to_csv(\"word_frequency.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d9806",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c173fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>Provider_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grass</td>\n",
       "      <td>207</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artificial</td>\n",
       "      <td>123</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawn</td>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garden</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>pleasing</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>stunning</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>hay</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>fever</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>dig</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Count  Provider_count\n",
       "0         grass    207              24\n",
       "1    artificial    123              24\n",
       "2          lawn     66              19\n",
       "3        garden     50              19\n",
       "4           pet     50              19\n",
       "..          ...    ...             ...\n",
       "260    pleasing      3               3\n",
       "261    stunning      3               3\n",
       "262         hay      3               3\n",
       "263       fever      3               3\n",
       "264         dig      3               3\n",
       "\n",
       "[226 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq[(word_freq[\"Count\"]>2) & (word_freq[\"Provider_count\"]>2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1eaab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data-clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
